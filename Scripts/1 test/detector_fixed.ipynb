{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6e1aa811-d1f8-4353-b55e-2015c1c9ce8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Using columns: URLs='URL', Labels='Label'\n",
      "Extracting features...\n",
      "Successfully processed 336749 URLs\n",
      "Label distribution:\n",
      "Label\n",
      "1    175806\n",
      "0    160943\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training model...\n",
      "Learned 100 trusted domains from training data\n",
      "Model trained and saved\n",
      "\n",
      "Sample of automatically learned trusted domains:\n",
      "['ac.in', 'gov.in', 'bel.tr', 'co.jp', 'go.jp', 'gov.uk', 'co.th', 'net.au', 'com.my', 'com.uy']\n",
      "\n",
      "==================================================\n",
      "PHISHING DETECTOR READY FOR INPUT\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter URL to check (or 'quit'):  https://www.facebook.com/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Analysis Result ===\n",
      "URL: https://www.facebook.com/\n",
      "Domain: facebook.com\n",
      "Status: PHISHING\n",
      "Confidence: high\n",
      "Probability: 99.96%\n",
      "Key Indicators:\n",
      "- High randomness (entropy: 3.83)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter URL to check (or 'quit'):  https://www.kaggle.com/datasets/naserabdullahalam/phishing-email-dataset/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Analysis Result ===\n",
      "URL: https://www.kaggle.com/datasets/naserabdullahalam/phishing-email-dataset/\n",
      "Domain: kaggle.com\n",
      "Status: PHISHING\n",
      "Confidence: high\n",
      "Probability: 99.99%\n",
      "Key Indicators:\n",
      "- High randomness (entropy: 4.17)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter URL to check (or 'quit'):  quit\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse\n",
    "import math\n",
    "import re\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "# 1. Enhanced Feature Extraction (unchanged)\n",
    "def extract_url_features(url):\n",
    "    \"\"\"Extracts phishing detection features from any URL\"\"\"\n",
    "    try:\n",
    "        parsed = urlparse(url)\n",
    "        domain = parsed.netloc.split(':')[0]\n",
    "        \n",
    "        features = {\n",
    "            'url_length': len(url),\n",
    "            'domain_has_ip': int(bool(re.match(r'^\\d+\\.\\d+\\.\\d+\\.\\d+$', domain))),\n",
    "            'num_special_chars': sum(1 for c in url if c in '/:?&%=.-_~@'),\n",
    "            'num_digits': sum(c.isdigit() for c in url),\n",
    "            'domain_length': len(domain),\n",
    "            'subdomain_length': len(domain.split('.')[0]),\n",
    "            'num_subdomains': len(domain.split('.')) - 1,\n",
    "            'is_common_tld': int(domain.endswith(('.com', '.org', '.net', '.gov'))),\n",
    "            'typosquatting': int(any(t in domain for t in ['paypa1', 'g00gle', 'amaz0n'])),\n",
    "            'has_banking_kw': int(any(kw in url.lower() for kw in ['login', 'bank', 'account', 'secure'])),\n",
    "            'has_hex': int(bool(re.search(r'%[0-9a-fA-F]{2}', url))),\n",
    "            'has_at_symbol': int('@' in url),\n",
    "            'uses_https': int(parsed.scheme == 'https'),\n",
    "            'path_depth': parsed.path.count('/'),\n",
    "            'entropy': -sum((url.count(c)/len(url)) * math.log2(url.count(c)/len(url)) \n",
    "                       for c in set(url) if url.count(c) > 0),\n",
    "            'vowel_ratio': sum(1 for c in domain if c.lower() in 'aeiou') / len(domain) if domain else 0,\n",
    "            'consecutive_chars': int(bool(re.search(r'([a-zA-Z])\\1{2}', domain))),\n",
    "        }\n",
    "        return features\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# 2. Phishing Detector Class with Dynamic Domain Learning\n",
    "class PhishingDetector:\n",
    "    def __init__(self, model_path=None):\n",
    "        self.model = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', LGBMClassifier(\n",
    "                n_estimators=200,\n",
    "                max_depth=7,\n",
    "                class_weight='balanced',\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "        self.trusted_domains = set()  # Will be learned from data\n",
    "        self.domain_reputation = defaultdict(int)\n",
    "        \n",
    "        if model_path:\n",
    "            try:\n",
    "                saved_data = joblib.load(model_path)\n",
    "                self.model = saved_data['model']\n",
    "                self.trusted_domains = set(saved_data.get('trusted_domains', []))\n",
    "                print(\"Loaded pre-trained model with dynamic domain knowledge\")\n",
    "            except:\n",
    "                print(\"Could not load model, using untrained model\")\n",
    "\n",
    "    def _extract_base_domain(self, url):\n",
    "        \"\"\"Extracts base domain (e.g. 'google.com' from 'mail.google.com')\"\"\"\n",
    "        domain = urlparse(url).netloc.lower()\n",
    "        if domain.startswith('www.'):\n",
    "            domain = domain[4:]\n",
    "        parts = domain.split('.')\n",
    "        if len(parts) > 2:\n",
    "            return f\"{parts[-2]}.{parts[-1]}\"\n",
    "        return domain\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"Train model and learn trusted domains\"\"\"\n",
    "        # Extract domains from training data\n",
    "        domains = [self._extract_base_domain(url) for url in X.index]\n",
    "        legit_domains = [d for d, label in zip(domains, y) if label == 0]\n",
    "        \n",
    "        # Calculate domain frequencies\n",
    "        domain_counts = pd.Series(legit_domains).value_counts()\n",
    "        \n",
    "        # Automatically identify trusted domains (top 100 legitimate domains)\n",
    "        self.trusted_domains = set(domain_counts.head(100).index)\n",
    "        print(f\"Learned {len(self.trusted_domains)} trusted domains from training data\")\n",
    "        \n",
    "        # Train the model\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def save_model(self, path):\n",
    "        \"\"\"Save model with learned domain knowledge\"\"\"\n",
    "        joblib.dump({\n",
    "            'model': self.model,\n",
    "            'trusted_domains': list(self.trusted_domains)\n",
    "        }, path)\n",
    "\n",
    "    def is_trusted_domain(self, url):\n",
    "        \"\"\"Dynamic domain verification\"\"\"\n",
    "        domain = self._extract_base_domain(url)\n",
    "        return domain in self.trusted_domains\n",
    "\n",
    "    def predict(self, url):\n",
    "        \"\"\"Predict with dynamic domain analysis\"\"\"\n",
    "        if not url.startswith(('http://', 'https://')):\n",
    "            url = 'https://' + url\n",
    "            \n",
    "        domain = self._extract_base_domain(url)\n",
    "        \n",
    "        # Dynamic trusted domain check\n",
    "        if self.is_trusted_domain(url):\n",
    "            return {\n",
    "                'url': url,\n",
    "                'is_phishing': False,\n",
    "                'confidence': 'high',\n",
    "                'message': f'Automatically verified domain: {domain}',\n",
    "                'probability': 0.01,  # Very low probability for trusted domains\n",
    "                'indicators': [f'Trusted domain pattern: {domain}']\n",
    "            }\n",
    "\n",
    "        features = extract_url_features(url)\n",
    "        if not features:\n",
    "            return {\n",
    "                'url': url,\n",
    "                'is_phishing': None,\n",
    "                'error': 'Could not extract features',\n",
    "                'confidence': 'low'\n",
    "            }\n",
    "\n",
    "        try:\n",
    "            features_df = pd.DataFrame([features])\n",
    "            proba = self.model.predict_proba(features_df)[0][1]\n",
    "            \n",
    "            # Adjust confidence based on domain characteristics\n",
    "            if domain.endswith(('.gov', '.edu', '.mil')):\n",
    "                proba *= 0.5  # Reduce suspicion for government/education domains\n",
    "                \n",
    "            is_phishing = proba > 0.85\n",
    "            \n",
    "            indicators = []\n",
    "            if features['domain_has_ip']:\n",
    "                indicators.append(\"Uses IP address instead of domain\")\n",
    "            if features['typosquatting']:\n",
    "                indicators.append(\"Contains typosquatting patterns\")\n",
    "            if features['entropy'] > 3.5:\n",
    "                indicators.append(f\"High randomness (entropy: {features['entropy']:.2f})\")\n",
    "            \n",
    "            return {\n",
    "                'url': url,\n",
    "                'is_phishing': bool(is_phishing),\n",
    "                'probability': float(proba),\n",
    "                'confidence': 'high' if proba > 0.9 or proba < 0.1 else 'medium',\n",
    "                'domain': domain,\n",
    "                'indicators': indicators if indicators else ['No strong indicators']\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'url': url,\n",
    "                'is_phishing': None,\n",
    "                'error': str(e),\n",
    "                'confidence': 'low'\n",
    "            }\n",
    "\n",
    "# 3. Main Execution (updated to track domains)\n",
    "if __name__ == \"__main__\":\n",
    "    detector = PhishingDetector()\n",
    "    \n",
    "    try:\n",
    "        print(\"Loading dataset...\")\n",
    "        data = pd.read_csv('C:/Users/msi/OneDrive/Bureau/CyberIA/StealthPhisher2025.csv')\n",
    "        \n",
    "        # Auto-detect columns\n",
    "        url_col = next((col for col in data.columns if 'url' in col.lower()), 'URL')\n",
    "        label_col = next((col for col in data.columns if col.lower() in ['label', 'phishing']), 'Label')\n",
    "        \n",
    "        print(f\"Using columns: URLs='{url_col}', Labels='{label_col}'\")\n",
    "        \n",
    "        # Convert labels\n",
    "        label_mapping = {\n",
    "            'legitimate': 0, 'phishing': 1, 'safe': 0, 'malicious': 1,\n",
    "            '0': 0, '1': 1, 'false': 0, 'true': 1\n",
    "        }\n",
    "        y = data[label_col].astype(str).str.lower().map(label_mapping)\n",
    "        \n",
    "        if y.isna().any():\n",
    "            invalid_labels = data[label_col][y.isna()].unique()\n",
    "            raise ValueError(f\"Found unmapped labels: {invalid_labels}\")\n",
    "        \n",
    "        # Extract features and track URLs for domain learning\n",
    "        print(\"Extracting features...\")\n",
    "        features = []\n",
    "        valid_indices = []\n",
    "        url_index = []  # To keep track of original URLs\n",
    "        \n",
    "        for i, url in enumerate(data[url_col]):\n",
    "            feat = extract_url_features(str(url))\n",
    "            if feat:\n",
    "                features.append(feat)\n",
    "                valid_indices.append(i)\n",
    "                url_index.append(url)\n",
    "        \n",
    "        X = pd.DataFrame(features, index=url_index)  # Store URLs in index\n",
    "        y = y.iloc[valid_indices].astype(int)\n",
    "        \n",
    "        print(f\"Successfully processed {len(X)} URLs\")\n",
    "        print(\"Label distribution:\")\n",
    "        print(y.value_counts())\n",
    "        \n",
    "        # Train model (will automatically learn domains)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        print(\"\\nTraining model...\")\n",
    "        detector.train(X_train, y_train)\n",
    "        detector.save_model('phishing_model.pkl')\n",
    "        print(\"Model trained and saved\")\n",
    "        \n",
    "        # Show some learned domains\n",
    "        print(\"\\nSample of automatically learned trusted domains:\")\n",
    "        print(list(detector.trusted_domains)[:10])\n",
    "        \n",
    "        # Interactive testing\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"PHISHING DETECTOR READY FOR INPUT\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        while True:\n",
    "            url = input(\"\\nEnter URL to check (or 'quit'): \").strip()\n",
    "            if url.lower() == 'quit':\n",
    "                break\n",
    "                \n",
    "            result = detector.predict(url)\n",
    "            print(\"\\n=== Analysis Result ===\")\n",
    "            print(f\"URL: {result['url']}\")\n",
    "            print(f\"Domain: {result.get('domain', 'N/A')}\")\n",
    "            print(\"Status:\", \"PHISHING\" if result.get('is_phishing') else \"SAFE\")\n",
    "            print(f\"Confidence: {result.get('confidence', 'unknown')}\")\n",
    "            if 'probability' in result:\n",
    "                print(f\"Probability: {result['probability']:.2%}\")\n",
    "            print(\"Key Indicators:\")\n",
    "            for indicator in result.get('indicators', ['No strong indicators']):\n",
    "                print(f\"- {indicator}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR: {str(e)}\")\n",
    "        print(\"\\nTroubleshooting Guide:\")\n",
    "        print(\"1. Verify CSV file exists and is accessible\")\n",
    "        print(\"2. Check column headers match expected format\")\n",
    "        print(\"3. Ensure URLs are properly formatted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc8692c-8a9b-4486-9d1c-3076dbfec5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
